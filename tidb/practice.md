# TiDB实践

这是结合之前一年多TiDB相关的数据工作，做的一个简单小结，希望对大家有一定价值。

## 定位

TiDB目前应该仅使用于读库、分析场景。

TiDB 在外的定位是HTAP,既有TP也有AP。但在TP的场景中，虽然在大表的写性能已经超过单机的mysql，但在没有经过充足的时间验证前，不应该使用于生产的主库(简单说，生产主库需要保稳)。

但在生产环节，如果是跨业务的，对数据的点查；或者是分库分表的大库的点查，TiDB作为`读库`还是很合适的。


在分析场景，`TiDB 只是hadoop的补充，不是完全替代`。

TiDB是特别适合我们公司目前的业务特征，具体表现在如下两方面：

* `存储` 绝大部分数据的是格式化的mysql数据，同时表多，单表数据相对不大。只有少数几个表特别大。却对数据更新的时效要求比较高。

* `计算` 查询上，特大的跑批任务数量不多，更多是用户临时的`实时`数据查询需求。

所以TiDB具体的定位应该是跟hadoop体系配套提供数据服务。具体的角色划分可以是这样的：

### hadoop体系

* 非结构化数据，如日志类数据
* 特大的跑批任务，如行数过亿的表，不过索引复杂join
* 数据更新时效要求在10分钟开外的，可以考虑结合hudi这类提供服务

### TiDB体系

* 数据更新时效要求高的数据需求，如要求与mysql主库保持分钟内同步的
* 工作上临时性数据查询，但对数据查询时效要求高（体现在并行性能比较好）


## TiDB实际落地过程中遇到的问题与解决方式

### `系统搭建` 数据副本配置

我们是单个物理机部署了两个TiKV实例，这样在什么都没做的情况下，可能两个raft 副本所在的TiKV实例分布在一台物理机上。

前期我们在kv侧配置了label，但是没有在pd配置，导致没有生效。这样如果一台物理机有问题down了，会导致部分数据不可用。

### `系统搭建` region 合并

TiKV的数据是通过raft实现的分布式一致性，具体实现的时候是对rocksdb上一段kv逻辑切分为region，然后进行管理。在我们什么都不做的情况，系统运行一段时间后，会导致region很零碎，类似hdfs上大量小文件。

我们的解决部分是，开启merge，包括random-merge(这个现在有点隐藏功能的味道，不能直接通过pd-ctl开启，需要http方式)。

### `系统搭建` 跨表region 合并

系统在使用跑批的场景下，会出现大量drop table或者truncate table，导致大量的空region，加重raft心跳负担。

这个问题的解决需要修改kv、pd的配置，并重启集群：

```
    TiKV split-region-on-table 设为 false
    PD namespace-classifier 设为 “”
```

### `数据同步` 大表数据的实时同步

大表数据的写入，在TiDB这边容易引发写热点，导致性能跟不上，在3.0之后的版本我们可以在建表时使用shard_row_id_bits把数据打撒。 

### `系统维护` balance调大

如果集群region数量多，在gc的时候还是偶尔会抖动，这时候主要是单机资源使用太高，我们可以通过balance方式，将压力调度出去。

这边需要将leader-balance、region-balance都调大。当然包括读写的热点调度。

### `系统维护` 集群重启后，raft无法选主

还是老问题，在集群region数量过多的时候，如果我们重启TiKV，可能出现raft选主迟迟无法完成。这个的瓶颈主要还是在网络。

临时的处理办法是将raft的心跳时间调大。


### `推广` 用户使用过程的质疑、疑问

用户在刚使用TiDB时，由于对新技术不了解会提出很多让人措手不及的问题。

我们的解决办法是：

* 选团队一点点推广
* `自证清白`我们log用户全部操作，并开放sql查询；面对用户的疑问，直接数据说话，核对使用情况。这样可以简单区分用户问题是使用的，还是确实系统问题。

### haproxy 下资源分配不均衡

在用户大规模使用后，我们使用了haproxy来做负载均衡。但haproxy最适合的策略是least-conn，粒度还是太粗，TiDB计算层任务差异太大。

我们是通过修改TiDB源码，提供了http-chk来让haproxy检查TiDB节点的健康，如果资源所剩不多，会不再分发新链接到这个实例。


### TiDB 资源有限情况下的维稳

部分用户会在TiDB上投递占用资源高达100G的sql，有时还会频繁投递，严重影响其他用户。

在不能部署专用机器的情况，我们进行服务分级：

* 资源随便用，但不保障稳定
* 资源使用受限，但保障稳定

### `脚本跑批` 百万行及以上数据写入困难

这个问题，其实是因为单次数据写入太多，2pc出差概率高导致。

由于我们跑批的场景，单表一般只有一个client在写，所以冲突概率不高，所以我们修改代码将单次数据写入量调大。同时也可以使用batch_insert取消事务解决。

### `脚本跑批` 在数据量大的情况下，推荐drop table

在TiDB上delete数据，其实底层是写入一个delete标记，最后在compaction的时候才清理，所以在大批量删除数据时，推荐使用drop table而非delete。
